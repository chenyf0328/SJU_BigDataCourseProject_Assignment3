library(sparklyr)
library(dplyr)

# connect to Spark using a local instance running on host computer
sc <- spark_connect(master = "local")

# read data from host machine to R dataFrame. Tips: If read in arff file extension. The feature generated by DT will become wired.
getwd()
setwd("F:\\Saint Joseph's University\\Course\\Big Data\\BigDataCode\\PhishingWebSite\\data")
R_df <- read.csv("PhishingData.csv", header=TRUE, sep=",")
# transfer R dataFrame into spark dataFrame, otherwise we cannot use ml_decision_tree() method 
Sparkly_df <- copy_to(sc , R_df)

# split data set into 70% training and 30% test, set seed to 1000 to add randomness when spliting
partitions <- Sparkly_df %>% sdf_partition(training = 0.7, test = 0.3, seed = 1000)

# set the formula for decision tree, Result, SFH, popUpWidow and other features
ml_formula <- formula(Result ~  SFH + popUpWidnow + SSLfinal_State + Request_URL + URL_of_Anchor + web_traffic + URL_Length + age_of_domain + having_IP_Address)

# use training data to generate decision tree. Parameters: forula; type is classification, because in this question,
# we aim to classify if it's phishing WebSite. Not regression, it used for linear question; impurity is entropy, 
# it depended on our type value, classification -> entropy; max.bins; max.depth; seed
model <- partitions$training %>% ml_decision_tree(ml_formula, type = "classification", impurity = "entropy", max.bins = 16L, max.depth = 16L, seed = 42L)

# output this decision tree
spark_jobj(model$model) %>% invoke("toDebugString") %>% cat()

# predict decision tree using test data and generate the accuracy
pred_phishing <- sdf_predict(model, partitions$test)
ml_classification_eval(pred_phishing)